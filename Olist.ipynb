{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Olist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stormyCobra1199/olist/blob/main/Olist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**bOwLISTIC 5**\n",
        "\n",
        "Prep ipynb for OLIST data ingestion workflow.\n",
        "To be used in conjunction with olistDAG.py DAG.\n"
      ],
      "metadata": {
        "id": "QVAEstHMjmSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCHEMA PLAN (9 Tables in total)\n",
        "\n",
        "sellers:\n",
        "*   seller_id str \n",
        "*   seller_zip_code_prefix int\n",
        "*   seller_city str\n",
        "*   seller_state str\n",
        "\n",
        "customers:\n",
        "*   customer_id str\n",
        "*   customer_unique_id str\n",
        "*   customer_zip_code_prefix int\n",
        "*   customer_city str\n",
        "*   customer_state str\n",
        "\n",
        "category_name:\n",
        "*   product_category_name str\n",
        "*   product_category_name_english str\n",
        "\n",
        "products:\n",
        "*   product_id str\n",
        "*   product_category_name str\n",
        "*   product_name_lenght int\n",
        "*   product_description_lenght int\n",
        "*   product_photos_qty int\n",
        "*   product_weight_g int\n",
        "*   product_length_cm int\n",
        "*   product_height_cm int\n",
        "*   product_width_cm int\n",
        "\n",
        "orders:\n",
        "*   order_id str\n",
        "*   customer_id str\n",
        "*   order_status str\n",
        "*   order_purchase_timestamp str\n",
        "*   order_approved_at str\n",
        "*   order_delivered_carrier_date str\n",
        "*   order_delivered_customer_date str\n",
        "*   order_estimated_delivery_date str\n",
        "\n",
        "order_items:\n",
        "*   order_id str\n",
        "*   order_item_id int\n",
        "*   product_id str\n",
        "*   seller_id str\n",
        "*   shipping_limit_date str\n",
        "*   price float\n",
        "*   freight_value float\n",
        "\n",
        "order_payments:\n",
        "*   order_id str\n",
        "*   payment_sequential int\n",
        "*   payment_type str\n",
        "*   payment_installments int\n",
        "*   payment_value float\n",
        "\n",
        "order_reviews:\n",
        "*   review_id str\n",
        "*   order_id str\n",
        "*   review_score int\n",
        "*   review_comment_title str\n",
        "*   review_comment_message str\n",
        "*   review_creation_date str\n",
        "*   review_answer_timestamp str\n",
        "\n",
        "geolocation:\n",
        "*   geolocation_zip_code_prefix int\n",
        "*   geolocation_lat str (see note below)\n",
        "*   geolocation_lng str (see note below)\n",
        "*   geolocation_city str\n",
        "*   geolocation_state str\n",
        "\n",
        "Note: A float or double is a binary value and does not have a well defined number of decimal places.\n",
        "\n",
        "\"Decimal places\" have meaning only when you print the number.\n",
        "\n",
        "To store latitude and longitude values and maintain full accuracy, store either the text string as received from the GPS unit, or store the long integer values maintained internally by TinyGPS. You will lose accuracy if you save the float value. -- from https://forum.arduino.cc/t/storing-latitute-and-longitude-using-a-double/670691/4 "
      ],
      "metadata": {
        "id": "xlDTZhuN-RP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLEANING REQUIRED (By Table)\n",
        "*   OK sellers\n",
        "*   OK customers\n",
        "*   NOK geolocation (name odd chars)\n",
        "*   NOK products (missing cat, name, description)\n",
        "*   OK category_name (ignore english misspellings)\n",
        "*   OK orders (some missing fields but intended due to delivery status)\n",
        "*   OK order_items\n",
        "*   NOK order_reviews (comment title and comment msg blanks n messy)\n",
        "*   OK order_payments"
      ],
      "metadata": {
        "id": "epNIgqcayNTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### PULL CSV from Google Drive\n",
        "import pandas as pd\n",
        "# Libraries to read csv file hosted on Google Drive into Google Colab:\n",
        "!pip install python-tds\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# The shareable links from Google Drive for each CSV file hosted there\n",
        "sellers_link = '1cG5h5AW0hE7OmDZ0YPtZLVSVDnL7mCkQ' \n",
        "category_name_link = '1Y1oiP5U1jBO0Ji5FJyRYKULw1T953obp'\n",
        "products_link = '1L8a9t3obUYIH0RzCfaCcqil7rkjgHOb-'\n",
        "order_reviews_link = '1_XXIOg3_rDSGKW61EI7MIZ0UqYYpLzfU'\n",
        "orders_link = '1PaeE67IdrWocbY5isimVwezk7EQK5pAn'\n",
        "order_payments_link = '1Tfrf7yof8pYXcK4pFuVRt28rWwW9BW4F'\n",
        "order_items_link = '1IwOvsLbP6ub9BDsXq-FWbd3d7yl1ZJvI'\n",
        "geolocation_link = '1yL1iSIwMjskL_kKza6kQH8TuI566lYnu'\n",
        "customers_link = '10cfto60JXwwIe8lewY2dao3KB9TSOuu8'\n",
        "\n",
        "# Pull the Google Drive hosted CSVs\n",
        "print(\"Loading CSV...\")\n",
        "\n",
        "downloaded = drive.CreateFile({'id':sellers_link}) \n",
        "downloaded.GetContentFile('olist_sellers_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':category_name_link}) \n",
        "downloaded.GetContentFile('product_category_name_translation.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':products_link}) \n",
        "downloaded.GetContentFile('olist_products_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':order_reviews_link}) \n",
        "downloaded.GetContentFile('olist_order_reviews_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':orders_link}) \n",
        "downloaded.GetContentFile('olist_orders_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':order_payments_link}) \n",
        "downloaded.GetContentFile('olist_order_payments_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':order_items_link}) \n",
        "downloaded.GetContentFile('olist_order_items_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':geolocation_link}) \n",
        "downloaded.GetContentFile('olist_geolocation_dataset.csv')  \n",
        "\n",
        "downloaded = drive.CreateFile({'id':customers_link}) \n",
        "downloaded.GetContentFile('olist_customers_dataset.csv')  \n",
        "\n",
        "print(\"all CSV downloaded!\\n\")\n"
      ],
      "metadata": {
        "id": "Zskhdq5rXo3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c870741-58bc-425b-8be0-2b9a06f28211"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-tds in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from python-tds) (1.15.0)\n",
            "Loading CSV...\n",
            "all CSV downloaded!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# airflow libs install\n",
        "!pip install apache-airflow\n",
        "!pip install apache-airflow[cncf.kubernetes]"
      ],
      "metadata": {
        "id": "r3idpAeSE91v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!airflow db init\n",
        "!airflow version"
      ],
      "metadata": {
        "id": "ExMvDUptFkxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir /content/dags  #remember to add olistDAG.py \n",
        "#!airflow tasks run odag tryprint '2022-04-27T00:00:00+00:00'\n",
        "!airflow dags test odag '2022-04-27T00:00:00+00:00'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjK4ZOGUGRJR",
        "outputId": "1af8431f-a3cd-44d7-f152-9cc96dee2e89"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33m/usr/local/lib/python3.7/dist-packages/psycopg2/\u001b[0m\u001b[1;33m__init__.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m144\u001b[0m\u001b[1;33m UserWarning\u001b[0m\u001b[33m: The psycopg2 wheel package will be renamed from release \u001b[0m\u001b[1;33m2.8\u001b[0m\u001b[33m; in order to keep installing from binary please use \u001b[0m\u001b[33m\"pip install psycopg2-binary\"\u001b[0m\u001b[33m instead. For details see: \u001b[0m\u001b[1;33m<\u001b[0m\u001b[4;33mhttp:\u001b[0m\u001b[4;33m//initd.org/psycopg/docs/install.html#binary-install-from-pypi\u001b[0m\u001b[1;33m>\u001b[0m\u001b[33m.\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,568\u001b[0m] {\u001b[34mdagbag.py:\u001b[0m500} INFO\u001b[0m - Filling up the DagBag from \u001b[1m/content/dags\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,631\u001b[0m] {\u001b[34mtutorial_taskflow_api_etl_virtualenv.py:\u001b[0m30} \u001b[33mWARNING\u001b[0m - \u001b[33mThe tutorial_taskflow_api_etl_virtualenv example DAG requires virtualenv, please install it.\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,646\u001b[0m] {\u001b[34mexample_python_operator.py:\u001b[0m68} \u001b[33mWARNING\u001b[0m - \u001b[33mThe virtalenv_python example task requires virtualenv, please install it.\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,809\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.tryinit backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,838\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.loadpip1 backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,867\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.loadpip2 backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,897\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.loadgc backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,925\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.createbqtables backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:24,956\u001b[0m] {\u001b[34mbase_executor.py:\u001b[0m85} INFO\u001b[0m - Adding to queue: \u001b[1m['<TaskInstance: odag.csv2bq backfill__2022-04-27T00:00:00+00:00 [queued]>']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,784\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=tryinit\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,807\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mtryinit\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T123535\u001b[22m, end_date=\u001b[1m20220428T134329\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,868\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=loadpip1\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,869\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m62} INFO\u001b[0m - Tmp dir root location: \n",
            " \u001b[1m/tmp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,869\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m74} INFO\u001b[0m - Running command: \u001b[1m['bash', '-c', 'pip install python-tds']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:29,877\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m85} INFO\u001b[0m - Output:\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:30,475\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m89} INFO\u001b[0m - \u001b[1mRequirement already satisfied: python-tds in /usr/local/lib/python3.7/dist-packages (1.11.0)\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:30,478\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m89} INFO\u001b[0m - \u001b[1mRequirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from python-tds) (1.15.0)\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,324\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m93} INFO\u001b[0m - Command exited with return code 0\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,348\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mloadpip1\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T122201\u001b[22m, end_date=\u001b[1m20220428T134336\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,421\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=loadpip2\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,422\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m62} INFO\u001b[0m - Tmp dir root location: \n",
            " \u001b[1m/tmp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,423\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m74} INFO\u001b[0m - Running command: \u001b[1m['bash', '-c', 'pip install -U -q PyDrive']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:36,433\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m85} INFO\u001b[0m - Output:\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,292\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m93} INFO\u001b[0m - Command exited with return code 0\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,315\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mloadpip2\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T122201\u001b[22m, end_date=\u001b[1m20220428T134343\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,386\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=loadgc\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,387\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m62} INFO\u001b[0m - Tmp dir root location: \n",
            " \u001b[1m/tmp\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,387\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m74} INFO\u001b[0m - Running command: \u001b[1m['bash', '-c', 'gcloud config set project precise-victory-348205']\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:43,397\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m85} INFO\u001b[0m - Output:\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:45,283\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m89} INFO\u001b[0m - \u001b[1mUpdated property [core/project].\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:45,546\u001b[0m] {\u001b[34msubprocess.py:\u001b[0m93} INFO\u001b[0m - Command exited with return code 0\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:45,573\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mloadgc\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T125628\u001b[22m, end_date=\u001b[1m20220428T134345\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:45,647\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=createbqtables\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:45,806\u001b[0m] {\u001b[34mutils.py:\u001b[0m159} INFO\u001b[0m - NumExpr defaulting to 2 threads.\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:46,237\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "Created table precise-victory-348205.olist.sellers\n",
            "Created table precise-victory-348205.olist.customers\n",
            "Created table precise-victory-348205.olist.category_name\n",
            "Created table precise-victory-348205.olist.products\n",
            "Created table precise-victory-348205.olist.orders\n",
            "Created table precise-victory-348205.olist.order_items\n",
            "Created table precise-victory-348205.olist.order_payments\n",
            "Created table precise-victory-348205.olist.order_reviews\n",
            "Created table precise-victory-348205.olist.geolocation\n",
            "[\u001b[34m2022-04-28 13:43:49,681\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mcreatebqtables\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T121223\u001b[22m, end_date=\u001b[1m20220428T134349\u001b[22m\u001b[0m\n",
            "[\u001b[34m2022-04-28 13:43:49,756\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1448} INFO\u001b[0m - Exporting the following env vars:\n",
            "\u001b[1mAIRFLOW_CTX_DAG_EMAIL=208108@gmail.com\n",
            "AIRFLOW_CTX_DAG_OWNER=ming\n",
            "AIRFLOW_CTX_DAG_ID=odag\n",
            "AIRFLOW_CTX_TASK_ID=csv2bq\n",
            "AIRFLOW_CTX_EXECUTION_DATE=2022-04-27T00:00:00+00:00\n",
            "AIRFLOW_CTX_DAG_RUN_ID=backfill__2022-04-27T00:00:00+00:00\u001b[22m\u001b[0m\n",
            "Ingesting CSV into DF...\n",
            "all CSV loaded in DF!\n",
            "\n",
            "Now to insert into BigQuery tables...\n",
            "[\u001b[34m2022-04-28 13:43:52,834\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.sellers\n",
            "Loaded 3095 rows and 4 columns to precise-victory-348205.olist.sellers\n",
            "[\u001b[34m2022-04-28 13:44:03,902\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.customers\n",
            "Loaded 99441 rows and 5 columns to precise-victory-348205.olist.customers\n",
            "[\u001b[34m2022-04-28 13:44:24,658\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.category_name\n",
            "Loaded 71 rows and 2 columns to precise-victory-348205.olist.category_name\n",
            "[\u001b[34m2022-04-28 13:44:33,714\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.products\n",
            "Loaded 32951 rows and 9 columns to precise-victory-348205.olist.products\n",
            "[\u001b[34m2022-04-28 13:44:43,873\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.orders\n",
            "Loaded 99441 rows and 8 columns to precise-victory-348205.olist.orders\n",
            "[\u001b[34m2022-04-28 13:45:13,159\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.order_items\n",
            "Loaded 112650 rows and 7 columns to precise-victory-348205.olist.order_items\n",
            "[\u001b[34m2022-04-28 13:45:33,095\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.order_payments\n",
            "Loaded 103886 rows and 5 columns to precise-victory-348205.olist.order_payments\n",
            "[\u001b[34m2022-04-28 13:45:51,443\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.order_reviews\n",
            "Loaded 100000 rows and 7 columns to precise-victory-348205.olist.order_reviews\n",
            "[\u001b[34m2022-04-28 13:46:18,542\u001b[0m] {\u001b[34m_default.py:\u001b[0m484} \u001b[33mWARNING\u001b[0m - \u001b[33mNo project ID could be determined. Consider running `gcloud config set project` or setting the \u001b[1mGOOGLE_CLOUD_PROJECT\u001b[22m environment variable\u001b[0m\n",
            "===> Loading DF to BQ table precise-victory-348205.olist.geolocation\n",
            "Loaded 1000163 rows and 5 columns to precise-victory-348205.olist.geolocation\n",
            "done!\n",
            "\n",
            "[\u001b[34m2022-04-28 13:47:16,579\u001b[0m] {\u001b[34mtaskinstance.py:\u001b[0m1288} INFO\u001b[0m - \u001b[1m\u001b[22mMarking task as \u001b[1mSUCCESS\u001b[22m. dag_id=\u001b[1modag\u001b[22m, task_id=\u001b[1mcsv2bq\u001b[22m, execution_date=\u001b[1m20220427T000000\u001b[22m, start_date=\u001b[1m20220428T123535\u001b[22m, end_date=\u001b[1m20220428T134716\u001b[22m\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/airflow\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/__main__.py\", line 48, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/cli/cli_parser.py\", line 48, in command\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\", line 70, in wrapper\n",
            "    return func(*args, session=session, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/cli.py\", line 92, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/cli/commands/dag_command.py\", line 418, in dag_test\n",
            "    run_at_least_once=True,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/models/dag.py\", line 2262, in run\n",
            "    job.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/jobs/base_job.py\", line 246, in run\n",
            "    self._execute()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\", line 70, in wrapper\n",
            "    return func(*args, session=session, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/jobs/backfill_job.py\", line 826, in _execute\n",
            "    session=session,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\", line 67, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/jobs/backfill_job.py\", line 739, in _execute_dagruns\n",
            "    session=session,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\", line 67, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/jobs/backfill_job.py\", line 634, in _process_backfill_task_instances\n",
            "    self._update_counters(ti_status=ti_status)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/utils/session.py\", line 70, in wrapper\n",
            "    return func(*args, session=session, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/airflow/jobs/backfill_job.py\", line 216, in _update_counters\n",
            "    ti_status.running.pop(reduced_key)\n",
            "KeyError: TaskInstanceKey(dag_id='odag', task_id='createbqtables', run_id='backfill__2022-04-27T00:00:00+00:00', try_number=6)\n"
          ]
        }
      ]
    }
  ]
}